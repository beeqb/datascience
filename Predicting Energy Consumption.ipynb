{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Appliance Energy Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:40:45.097237Z",
     "start_time": "2020-03-16T19:40:45.066458Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing, model_selection, metrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:10.868680Z",
     "start_time": "2020-03-16T19:27:10.859965Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:11.962876Z",
     "start_time": "2020-03-16T19:27:11.692474Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/jupyter/energydata_complete.csv\", parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:12.524936Z",
     "start_time": "2020-03-16T19:27:12.463411Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:13.798770Z",
     "start_time": "2020-03-16T19:27:13.766708Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:18.804936Z",
     "start_time": "2020-03-16T19:27:18.645008Z"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:19.430054Z",
     "start_time": "2020-03-16T19:27:19.415323Z"
    }
   },
   "outputs": [],
   "source": [
    "# presence of 0 whithin the df\n",
    "zero = 0\n",
    "for cols in df.columns:\n",
    "    if zero in df[cols]:\n",
    "        print('Found in '+cols) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables present at least a zero in their rilevation. This can be attributed to an error in the process of acquisiton information. \n",
    "Temperature, Humidity, Windspeed, Dew point obviously cannot be as low as 0 not even just for a single entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:21.559458Z",
     "start_time": "2020-03-16T19:27:21.524455Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check for Null values in df\n",
    "df.isnull().sum().sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This dataset is fully filled. \n",
    "### But are we sure that all the entries are useful? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:23.594073Z",
     "start_time": "2020-03-16T19:27:23.153587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find outliers\n",
    "sorted_appliances = df.sort_values('Appliances',ascending=False)\n",
    "print(\"The number of the 0,1% top values of Appliances' load is\",\n",
    "      len(sorted_appliances.head(len(sorted_appliances)//1000)),\"and they have power load higher than\",\n",
    "      sorted_appliances.Appliances[19], \"Wh.\")\n",
    "\n",
    "# boxplot appliances\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.boxplot(sorted_appliances.Appliances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:23.794533Z",
     "start_time": "2020-03-16T19:27:23.765618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing outliers\n",
    "df = df.dropna()\n",
    "df = df.drop(df[(df.Appliances>790)|(df.Appliances<0)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:25.527425Z",
     "start_time": "2020-03-16T19:27:25.518447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Columns based on type \n",
    "\n",
    "col_temp = [\"T1\",\"T2\",\"T3\",\"T4\",\"T5\",\"T6\",\"T7\",\"T8\",\"T9\"]\n",
    "\n",
    "col_hum = [\"RH_1\",\"RH_2\",\"RH_3\",\"RH_4\",\"RH_5\",\"RH_6\",\"RH_7\",\"RH_8\",\"RH_9\", \"RH_out\"]\n",
    "\n",
    "col_weather = [\"T_out\", \"Tdewpoint\",\"RH_out\",\"Press_mm_hg\",\n",
    "                \"Windspeed\",\"Visibility\"] \n",
    "col_light = [\"lights\"]\n",
    "\n",
    "col_randoms = [\"rv1\", \"rv2\"]\n",
    "\n",
    "col_target = [\"Appliances\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:25.799008Z",
     "start_time": "2020-03-16T19:27:25.794726Z"
    }
   },
   "outputs": [],
   "source": [
    "# variables divisions \n",
    "#feature_vars = [col_temp + col_hum + col_weather + col_light + col_randoms ]\n",
    "#target_var = [col_target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:25.995832Z",
     "start_time": "2020-03-16T19:27:25.988315Z"
    }
   },
   "outputs": [],
   "source": [
    "#feature_vars.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:26.141937Z",
     "start_time": "2020-03-16T19:27:26.137934Z"
    }
   },
   "outputs": [],
   "source": [
    "#target_var.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "1. Lights - More than 75% of the column is filled with zeros. I can't use any technique to replace those zeros, thus, for now it is bettere to remove it. In addition I can't use any fillied techniques to preserv it and it will negatively inflict the model I am going to apply.  \n",
    "\n",
    "2. Humidiy  - As expected the most humid place within the house is RH_5 (Bathroom) with a range between 29.82% to 96.32%. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:28.125601Z",
     "start_time": "2020-03-16T19:27:28.116982Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(['lights'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:31.124956Z",
     "start_time": "2020-03-16T19:27:31.120724Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:27:35.119225Z",
     "start_time": "2020-03-16T19:27:31.797374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the plotting layout\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (35,15))\n",
    "fig.autofmt_xdate(rotation = 45)\n",
    "\n",
    "# TEMPERATURE\n",
    "\n",
    "# Living Room \n",
    "ax1.plot(df.date, df['T2'], linewidth=1, alpha=.7, label = \"Living Room\")\n",
    "ax1.set_xlabel('Nov 1st 2016 - May 27th 2016'); ax1.set_ylabel('Temp in Celsius'); ax1.set_title('Temperature Trend')\n",
    "# Parents Room \n",
    "ax1.plot(df.date, df['T9'], linewidth=1, alpha=.7, label = \"Parents Room\")\n",
    "ax1.set_xlabel('Nov 1st 2016 - May 27th 2016');\n",
    "# Ironing Room \n",
    "ax1.plot(df.date, df['T7'], linewidth=1, alpha=.7, label = \"Ironing Room\")\n",
    "ax1.set_xlabel('Nov 1st 2016 - May 27th 2016'); \n",
    "ax1.legend()\n",
    "\n",
    "# HUMIDITY Outside vs HUMIDITY Wheather Station\n",
    "\n",
    "# Outiside\n",
    "ax2.plot(df.date, df.RH_6, linewidth=1, alpha=.7, label = \"North Outside House\")\n",
    "ax2.set_xlabel('Nov 1st 2016 - May 27th 2016'); ax2.set_ylabel('Humidity in %'); ax2.set_title('Humidity Trend')\n",
    "# Weather Station\n",
    "ax2.plot(df.date, df.RH_out, linewidth=1, alpha=.7, label = \"Weather Station\")\n",
    "ax2.set_xlabel('Nov 1st 2016 - May 27th 2016')\n",
    "ax2.legend()\n",
    "\n",
    "# OUTSIDE HUMIDITY (maybe fog?) vs VISIBILITY \n",
    "\n",
    "# Windspeed\n",
    "ax3.plot(df.date, df.RH_out, linewidth=1, alpha=.7, label=\"Outside Humidity\")\n",
    "ax3.set_xlabel('Nov 1st 2016 - May 27th 2016'), ax3.set_title('Humidity vs Visibility')\n",
    "# Visibility\n",
    "ax3.plot(df.date, df.Visibility, linewidth=1, alpha=.7, label=\"Visibility\")\n",
    "ax3.set_xlabel('Nov 1st 2016 - May 27th 2016')\n",
    "ax3.legend()\n",
    "\n",
    "\n",
    "# TEMPERATURE Outside vs TEMPERATURE Wheather Station\n",
    "# Outiside\n",
    "ax4.plot(df.date, df.T6, linewidth=1, alpha=.7, label = \"North Outside House\")\n",
    "ax4.set_xlabel('Nov 1st 2016 - May 27th 2016'); ax2.set_ylabel('Temp in Celsius'); ax4.set_title('Temperature Trend')\n",
    "# Weather Station\n",
    "ax4.plot(df.date, df.T_out, linewidth=1, alpha=.7, label = \"Weather Station\")\n",
    "ax4.set_xlabel('Nov 1st 2016 - May 27th 2016')\n",
    "ax4.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout(pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:17.252065Z",
     "start_time": "2020-03-16T19:28:08.849272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Histogram of all the features to understand the distribution\n",
    "df.hist(bins = 20 , figsize= (12,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:18.865432Z",
     "start_time": "2020-03-16T19:28:17.254483Z"
    }
   },
   "outputs": [],
   "source": [
    "# focused displots for RH_6 , RH_out , Visibility , Windspeed due to irregular distribution\n",
    "f, ax = plt.subplots(2,2,figsize=(12,8))\n",
    "vis1 = sns.distplot(df[\"RH_6\"],bins=10, ax=ax[0][0])\n",
    "vis2 = sns.distplot(df[\"RH_out\"],bins=10, ax=ax[0][1])\n",
    "vis3 = sns.distplot(df[\"Visibility\"],bins=10, ax=ax[1][0])\n",
    "vis4 = sns.distplot(df[\"Windspeed\"],bins=10, ax=ax[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome, another skewed distribution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:22.140090Z",
     "start_time": "2020-03-16T19:28:21.686450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of values in Applainces column\n",
    "f = plt.figure(figsize=(12,5))\n",
    "plt.xlabel('Appliance consumption in Wh')\n",
    "plt.ylabel('Frequency')\n",
    "sns.distplot(df[\"Appliances\"] , bins=10 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:24.485396Z",
     "start_time": "2020-03-16T19:28:24.480555Z"
    }
   },
   "outputs": [],
   "source": [
    "#log appliances\n",
    "df['log_appliances'] = np.log(df.Appliances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:25.378426Z",
     "start_time": "2020-03-16T19:28:24.987063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of values in log_appliances column\n",
    "f = plt.figure(figsize=(12,5))\n",
    "plt.xlabel('Appliance consumption in Wh')\n",
    "plt.ylabel('Frequency')\n",
    "sns.distplot(df[\"log_appliances\"] , bins=10 ) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:27.266109Z",
     "start_time": "2020-03-16T19:28:27.247758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop date column, I can add it later on\n",
    "df = df.drop(\"date\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:27.744113Z",
     "start_time": "2020-03-16T19:28:27.736968Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's remove humidity's columns for this first trial, I can add it later on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:34.591100Z",
     "start_time": "2020-03-16T19:28:34.585397Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = df.drop(col_hum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Targets and Convert Data to Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:39.722483Z",
     "start_time": "2020-03-16T19:28:39.701231Z"
    }
   },
   "outputs": [],
   "source": [
    "# Labels are the values we want to predict\n",
    "labels = np.array(df['log_appliances'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= df.drop(['log_appliances', 'Appliances'], axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline is the error we would get if we simply predict the average consumption in Watt/hour for Appliances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:41.341651Z",
     "start_time": "2020-03-16T19:28:41.337645Z"
    }
   },
   "outputs": [],
   "source": [
    "### TODO: TROVARE UNA STRATEGIA PER STABILIRE UNA BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:41.828865Z",
     "start_time": "2020-03-16T19:28:41.825617Z"
    }
   },
   "outputs": [],
   "source": [
    "# The baseline predictions is the average value of Watt/hour\n",
    "#baseline_preds = test_features[:, feature_list.index('Appliances')]\n",
    "# Baseline errors, and display average baseline error\n",
    "#baseline_errors = abs(baseline_preds - test_labels)\n",
    "#print('Average baseline error: ', round(np.mean(baseline_errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:44.843233Z",
     "start_time": "2020-03-16T19:28:44.824021Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "# with test_siz = 0.33 I get a Training Set to small, let's set it to .025\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:28:46.197714Z",
     "start_time": "2020-03-16T19:28:46.189188Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:34:38.288617Z",
     "start_time": "2020-03-16T19:28:47.827956Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 1234)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:34:41.444529Z",
     "start_time": "2020-03-16T19:34:38.294010Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:34:41.472401Z",
     "start_time": "2020-03-16T19:34:41.456877Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T12:50:40.974169Z",
     "start_time": "2020-03-16T12:50:39.060047Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select one tree from the forest\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "tree = rf.estimators_[5]\n",
    "# Export in dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Convert it in png\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T10:54:27.362650Z",
     "start_time": "2020-03-16T10:50:57.435Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The depth of this tree is:', tree.tree_.max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The image is quite large with 45 layer's level!\n",
    "### Let's focus on just once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select just 3 levels among 35\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "# Select just one small\n",
    "tree_small = rf_small.estimators_[1]\n",
    "# Export as png\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "graph.write_png('small_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: there is a prevalence of Temperature features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T19:34:49.704920Z",
     "start_time": "2020-03-16T19:34:49.135354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sorting the second element in each tuple\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:27:51.037451Z",
     "start_time": "2020-03-16T22:27:50.568004Z"
    }
   },
   "outputs": [],
   "source": [
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances))) \n",
    "\n",
    "# List of features sorted from most to least important. Take the 2nd value from the list of tuple above\n",
    "sorted_importances = [importance[1] for importance in feature_importances]\n",
    "# Take the 1st value from the list of tuple above\n",
    "sorted_features = [importance[0] for importance in feature_importances]\n",
    "\n",
    "# Cumulative importances\n",
    "cumulative_importances = np.cumsum(sorted_importances)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "# Make a line graph\n",
    "plt.plot(x_values, cumulative_importances, 'b-')\n",
    "\n",
    "# Draw line at 95% of importance retained\n",
    "plt.hlines(y = 0.95, xmin=0, xmax=len(sorted_importances), color = 'r', linestyles = 'dotted')\n",
    "\n",
    "# Format x ticks and labels\n",
    "plt.xticks(x_values, sorted_features, rotation = 'vertical')\n",
    "\n",
    "# Axis labels and title\n",
    "plt.xlabel('Variable') \n",
    "plt.ylabel('Cumulative Importance')\n",
    "plt.title('Cumulative Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the contribution to the overall importance of each feature. The red dotted line is set at 95% of total importance accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:39:17.952726Z",
     "start_time": "2020-03-16T22:39:17.945406Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find number of features for cumulative importance of 95%\n",
    "# Add 1 because Python is zero-indexed\n",
    "print('Number of features for 95% importance:', np.where(cumulative_importances > 0.95)[0][0] + 1, \"on\", len(feature_list), \"total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:43:49.152596Z",
     "start_time": "2020-03-16T22:43:49.147084Z"
    }
   },
   "outputs": [],
   "source": [
    "print(sorted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consideration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First 3:\n",
    "- T2 : temperature in lviign room area\n",
    "- Press_mm_hg : is humidty in living room area in %\n",
    "- T3 : temperature laundry\n",
    "\n",
    "Remark: This is the prove on my small_tree.png analysis -> \"there is a prevalence of temperature features\"\n",
    "\n",
    "Last 3:\n",
    "- Visibilitiy: not surprising\n",
    "- Random variable 1: not surprising\n",
    "- Random variable 2: not surprising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a Forest Tree with the most 3 important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "#rf_most_important = RandomForestRegressor(n_estimators= 100, random_state=1234)\n",
    "# Extract the two most important features\n",
    "#important_indices = [feature_list.index('T2'), feature_list.index('Press_mm_hg'), feature_list.index('T3')]\n",
    "#train_important = train_features[:, important_indices]\n",
    "#test_important = test_features[:, important_indices]\n",
    "# Train the random forest\n",
    "#rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions and determine the error\n",
    "#predictions = rf_most_important.predict(test_important)\n",
    "#errors = abs(predictions - test_labels)\n",
    "# Display the performance metrics\n",
    "#print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "#mape = np.mean(100 * (errors / test_labels))\n",
    "#accuracy = 100 - mape\n",
    "#print('Accuracy:', round(accuracy, 2), '%.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Super! This means if we want to reduce the power computational stress we can work with top 3 features without losing model accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with the 5 most important feature and let's see what changes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New random forest with only the two most important variables\n",
    "#rf_most_important = RandomForestRegressor(n_estimators= 100, random_state=1234)\n",
    "# Extract the two most important features\n",
    "#important_indices = [feature_list.index('T2'), feature_list.index('Press_mm_hg'), feature_list.index('T3'), feature_list.index('T3'), feature_list.index('T8'), feature_list.index('Td')]\n",
    "#train_important = train_features[:, important_indices]\n",
    "#test_important = test_features[:, important_indices]\n",
    "# Train the random forest\n",
    "#rf_most_important.fit(train_important, train_labels)\n",
    "# Make predictions and determine the error\n",
    "#predictions = rf_most_important.predict(test_important)\n",
    "#errors = abs(predictions - test_labels)\n",
    "# Display the performance metrics\n",
    "#print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "#mape = np.mean(100 * (errors / test_labels))\n",
    "#accuracy = 100 - mape\n",
    "#print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the the prove we must use the whole model's feature. Ah, by the way, this is trivial, since the difference in every weighted features is quite small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improve the RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, a hyperparameter is a parameter whose value is set before the learning process begins. By contrast, the values of other parameters are derived via training. Hyperparameter tuning relies more on experimental results than theory, and thus the best method to determine the optimal settings is to try many different combinations evaluate the performance of each model. However, evaluating each model only on the training set can lead to one of the most fundamental problems in machine learning: overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:40:12.009028Z",
     "start_time": "2020-03-16T22:40:11.996775Z"
    }
   },
   "source": [
    "### Restrict to the Most Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These were the six features required to reach a total feature importance of 95% in the first improving random forest notebook. We will use only these features in order to speed up the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:44:45.314680Z",
     "start_time": "2020-03-16T22:44:45.229992Z"
    }
   },
   "outputs": [],
   "source": [
    "# Names of five importances accounting for 95% of total importance\n",
    "important_feature_names = ['T2', 'RH_1', 'RH_8', 'RH_9', 'RH_out', 'RH_3', 'RH_5', 'T8', 'Press_mm_hg', \n",
    "                           'T3', 'T4', 'RH_4', 'T6', 'RH_7', 'T1', 'RH_2', 'T5', 'RH_6', 'T7', 'T_out',\n",
    "                           'Tdewpoint', 'T9']\n",
    "\n",
    "# Find the columns of the most important features\n",
    "important_indices = [feature_list.index(feature) for feature in important_feature_names]\n",
    "\n",
    "# Create training and testing sets with only the important features\n",
    "important_train_features = train_features[:, important_indices]\n",
    "important_test_features = test_features[:, important_indices]\n",
    "\n",
    "# Sanity check on operations\n",
    "print('Important train features shape:', important_train_features.shape)\n",
    "print('Important test features shape:', important_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:45:03.570232Z",
     "start_time": "2020-03-16T22:45:03.565593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use only the most important features\n",
    "train_features = important_train_features[:]\n",
    "test_features = important_test_features[:]\n",
    "\n",
    "# Update feature list for visualizations\n",
    "feature_list = important_feature_names[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Default Random Forest to Determine Parameters¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:22:45.869865Z",
     "start_time": "2020-03-16T22:22:45.756102Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation - KFold CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T22:46:16.346028Z",
     "start_time": "2020-03-16T22:46:16.333327Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] #10\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt'] #2\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)] #10\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 * 11 * 2 * 3 * 3 * 10 = 3960 settings.\n",
    "- Will my 1,3 GHz Intel Core i5 survive?\n",
    "- Will be worth it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:31:12.014399Z",
     "start_time": "2020-03-16T22:46:25.322781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-16T23:31:12.028524Z",
     "start_time": "2020-03-16T23:27:39.238Z"
    }
   },
   "source": [
    "### Evaluate the default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "base_model.fit(train_features, train_labels)\n",
    "evaluate(base_model, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best random search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "evaluate(best_random, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                           scoring = 'neg_mean_absolute_error', cv = 3, \n",
    "                           n_jobs = -1, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "evaluate(best_grid, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Round of Grid Search¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [110, 120, None],\n",
    "    'max_features': [3, 4],\n",
    "    'min_samples_leaf': [5, 6, 7],\n",
    "    'min_samples_split': [10],\n",
    "    'n_estimators': [75, 100, 125]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search_ad = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                           scoring = 'neg_mean_absolute_error', cv = 3, \n",
    "                           n_jobs = -1, verbose = 2)\n",
    "\n",
    "grid_search_ad.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_ad.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_ad = grid_search_ad.best_estimator_\n",
    "evaluate(best_grid_ad, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model Parameters:\\n')\n",
    "pprint(best_grid.get_params())\n",
    "print('\\n')\n",
    "evaluate(best_grid, test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column to mark weekdays (0) and weekends(1) for time series evaluation , \n",
    "# \n",
    "# The day of the week with Monday=0, Sunday=6.\n",
    "# Return the day of the week. It is assumed the week starts on Monday, which is denoted by 0 and ends on Sunday which is denoted by 6. \n",
    "# This method is available on both Series with datetime values (using the dt accessor) or DatetimeIndex.\n",
    "\n",
    "df['WEEKDAY'] = ((pd.to_datetime(df['date']).dt.dayofweek)//5 == 1).astype(float)\n",
    "# There are 5472 weekend recordings \n",
    "df['WEEKDAY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find rows with weekday \n",
    "\n",
    "temp_weekend =  data[data['WEEKDAY'] == 1]\n",
    "\n",
    "# To understand the timeseries variation of the applaince energy consumption\n",
    "visData = go.Scatter( x= temp_weekend.date  ,  mode = \"lines\", y = temp_weekend.Appliances )\n",
    "layout = go.Layout(title = 'Appliance energy consumption measurement on weekend' , xaxis=dict(title='Date'), yaxis=dict(title='(Wh)'))\n",
    "fig = go.Figure(data=[visData],layout=layout)\n",
    "\n",
    "iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of all the features to understand the distribution\n",
    "feature_vars.hist(bins = 20 , figsize= (12,16)) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focussed displots for RH_6 , RH_out , Visibility , Windspeed due to irregular distribution\n",
    "f, ax = plt.subplots(2,2,figsize=(12,8))\n",
    "vis1 = sns.distplot(feature_vars[\"RH_6\"],bins=10, ax= ax[0][0])\n",
    "vis2 = sns.distplot(feature_vars[\"RH_out\"],bins=10, ax=ax[0][1])\n",
    "vis3 = sns.distplot(feature_vars[\"Visibility\"],bins=10, ax=ax[1][0])\n",
    "vis4 = sns.distplot(feature_vars[\"Windspeed\"],bins=10, ax=ax[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of values in Applainces column\n",
    "f = plt.figure(figsize=(12,5))\n",
    "plt.xlabel('Appliance consumption in Wh')\n",
    "plt.ylabel('Frequency')\n",
    "sns.distplot(target_vars , bins=10 ) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "1. Temperature - All the columns follow normal distribution except T9\n",
    "2. Humidity - All columns follow normal distribution except RH_6 and RH_out , primarly because these sensors are outside the house \n",
    "3. Appliance - This column is postively skewed , most the values are around mean 100 Wh . There are outliers in this column \n",
    "4. Visibilty - This column is negatively skewed\n",
    "5. Windspeed - This column is postively skewed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appliance column range with consumption less than 200 Wh\n",
    "print('Percentage of the appliance consumption is less than 200 Wh')\n",
    "print(((target_vars[target_vars <= 200].count()) / (len(target_vars)))*100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the weather , temperature , applainces and random column to see the correlation\n",
    "train_corr = train[col_temp + col_hum + col_weather +col_target+col_randoms]\n",
    "corr = train_corr.corr()\n",
    "# Mask the repeated values\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "  \n",
    "f, ax = plt.subplots(figsize=(16, 14))\n",
    "#Generate Heat Map, allow annotations and place floats in map\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\" , mask=mask,)\n",
    "    #Apply xticks\n",
    "plt.xticks(range(len(corr.columns)), corr.columns);\n",
    "    #Apply yticks\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "    #show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redundant_pairs(df):\n",
    "    '''Get diagonal and lower triangular pairs of correlation matrix'''\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "# Function to get top correlations \n",
    "\n",
    "def get_top_abs_correlations(df, n=5):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "print(\"Top Absolute Correlations\")\n",
    "print(get_top_abs_correlations(train_corr, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations based on correlation plot\n",
    "\n",
    "1. Temperature - All the temperature variables from T1-T9 and T_out have positive correlation with the target Appliances . For the indoortemperatures, the correlations are high as expected, since the ventilation is driven by the HRV unit and minimizes air temperature differences between rooms. Four columns have a high degree of correlation with T9 - T3,T5,T7,T8 also T6 & T_Out has high correlation (both temperatures from outside) . Hence T6 & T9 can be removed from training set as information provided by them can be provided by other fields.\n",
    "\n",
    "2. Weather attributes - Visibility, Tdewpoint, Press_mm_hg  have low correlation values\n",
    "\n",
    "3. Humidity - There are no significantly high  correlation cases (> 0.9) for humidity sensors.\n",
    "\n",
    "4. Random variables have no role to play\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training dataset into independent and dependent varibales\n",
    "train_X = train[feature_vars.columns] # features\n",
    "train_y = train[target_vars.columns]# target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split testing dataset into independent and dependent varibales\n",
    "test_X = test[feature_vars.columns] # features\n",
    "test_y = test[target_vars.columns] # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to conlusion made above below columns are removed\n",
    "train_X.drop([\"rv1\",\"rv2\",\"Visibility\",\"T6\",\"T9\"],axis=1 , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to conlusion made above below columns are removed\n",
    "test_X.drop([\"rv1\",\"rv2\",\"Visibility\",\"T6\",\"T9\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "# Create test and training set by including Appliances column\n",
    "\n",
    "train = train[list(train_X.columns.values) + col_target ] # add target to fit it as well features variable \n",
    "\n",
    "test = test[list(test_X.columns.values) + col_target ] # add target to fit it as well features variable \n",
    "\n",
    "# Create dummy test and training set to hold scaled values\n",
    "# sc = standardize features by removing the mean and scaling to unit variance\n",
    "# because estimators might behave badly if the individual features do not more or less look \n",
    "# like standard normally distributed data\n",
    "\n",
    "sc_train = pd.DataFrame(columns=train.columns , index=train.index)\n",
    "\n",
    "sc_train[sc_train.columns] = sc.fit_transform(train) # fit to data, then transform it.\n",
    "\n",
    "sc_test= pd.DataFrame(columns=test.columns , index=test.index)\n",
    "\n",
    "sc_test[sc_test.columns] = sc.fit_transform(test) # fit to data, then transform it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One fitted, we can remove Appliances (target) column from traininig set\n",
    "\n",
    "train_X =  sc_train.drop(['Appliances'] , axis=1)\n",
    "train_y = sc_train['Appliances']\n",
    "\n",
    "test_X =  sc_test.drop(['Appliances'] , axis=1)\n",
    "test_y = sc_test['Appliances']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation\n",
    "\n",
    "We will be looking at following Algorithms \n",
    "\n",
    "**Improved and not improved Linear regression models**\n",
    "\n",
    "1.Simple Linear Regression\n",
    "\n",
    "2.Ridge regression \n",
    "\n",
    "3.Lasso regression \n",
    "\n",
    "**Support Vector Machine**\n",
    "\n",
    "3.Support vector regression \n",
    "\n",
    "**Nearest neighbour Regressor**\n",
    "\n",
    "4.KNeighborsRegressor\n",
    "\n",
    "**Ensmble models**\n",
    "\n",
    "5.Random Forest Regressor\n",
    "\n",
    "6.Gradient Boosting Regressor\n",
    "\n",
    "7.ExtraTrees Regressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn import neighbors\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "           ['Linear: ', LinearRegression()],\n",
    "           ['Lasso: ', Lasso()],\n",
    "           ['Ridge: ', Ridge()],\n",
    "           ['KNeighborsRegressor: ',  neighbors.KNeighborsRegressor()],\n",
    "           ['SVR:' , SVR(kernel='rbf')],\n",
    "           ['RandomForest ',RandomForestRegressor()],\n",
    "           ['ExtraTreeRegressor :',ExtraTreesRegressor()],\n",
    "           ['GradientBoostingClassifier: ', GradientBoostingRegressor()] ,\n",
    "           ['XGBRegressor: ', xgb.XGBRegressor()] ,\n",
    "         ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all the proposed models and update the information in a list model_data\n",
    "import time\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model_data = []\n",
    "for name,curr_model in models :\n",
    "    curr_model_data = {}\n",
    "    curr_model.random_state = 78\n",
    "    curr_model_data[\"Name\"] = name\n",
    "    start = time.time()\n",
    "    curr_model.fit(train_X,train_y)\n",
    "    end = time.time()\n",
    "    curr_model_data[\"Train_Time\"] = end - start\n",
    "    curr_model_data[\"Train_R2_Score\"] = metrics.r2_score(train_y,curr_model.predict(train_X))\n",
    "    curr_model_data[\"Test_R2_Score\"] = metrics.r2_score(test_y,curr_model.predict(test_X))\n",
    "    curr_model_data[\"Test_RMSE_Score\"] = sqrt(mean_squared_error(test_y,curr_model.predict(test_X)))\n",
    "    model_data.append(curr_model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to dataframe\n",
    "df_models = pd.DataFrame(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x=\"Name\", y=['Test_R2_Score' , 'Train_R2_Score' , 'Test_RMSE_Score'], kind=\"bar\" , title = 'R2 Score Results' , figsize= (10,8)) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obervations\n",
    "\n",
    "1. Best results over test set are given by Extra Tree Regressor with R2 score of 0.57\n",
    "2. Least RMSE score is also by Extra Tree Regressor 0.65\n",
    "2. Lasso regularization over Linear regression was worst performing model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = [{\n",
    "              'max_depth': [80, 150, 200,250],\n",
    "              'n_estimators' : [100,150,200,250],\n",
    "              'max_features': [\"auto\", \"sqrt\", \"log2\"]\n",
    "            }]\n",
    "reg = ExtraTreesRegressor(random_state=40)\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = reg, param_grid = param_grid, cv = 5, n_jobs = -1 , scoring='r2' , verbose=2)\n",
    "grid_search.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuned parameter set\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best possible parameters for ExtraTreesRegressor\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 score on training set with tuned parameters\n",
    "\n",
    "grid_search.best_estimator_.score(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 score on test set with tuned parameters\n",
    "grid_search.best_estimator_.score(test_X,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE score on test set with tuned parameters\n",
    "\n",
    "np.sqrt(mean_squared_error(test_y, grid_search.best_estimator_.predict(test_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Based on parameter tunning step we can see that \n",
    "\n",
    "1. Best possible parameter combination are - 'max_depth': 80, 'max_features': 'sqrt', 'n_estimators': 200\n",
    "\n",
    "    \n",
    "2. Training set  R2 score of 1.0 may be signal of overfitting on training set \n",
    "\n",
    "\n",
    "3. Test set R2 score is 0.63 improvement over 0.57 achieved using untuned model\n",
    "\n",
    "\n",
    "4. Test set RMSE score is 0.60 improvement over 0.65 achieved using untuned model \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sorted list of features in order of importance\n",
    "feature_indices = np.argsort(grid_search.best_estimator_.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = grid_search.best_estimator_.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "names = [train_X.columns[i] for i in indices]\n",
    "# Create plot\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Create plot title\n",
    "plt.title(\"Feature Importance\")\n",
    "\n",
    "# Add bars\n",
    "plt.bar(range(train_X.shape[1]), importances[indices])\n",
    "\n",
    "# Add feature names as x-axis labels\n",
    "plt.xticks(range(train_X.shape[1]), names, rotation=90)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top 5 most important feature \n",
    "names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 5 least important feature \n",
    "names[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce test & training set to 5 feature set\n",
    "train_important_feature = train_X[names[0:5]]\n",
    "test_important_feature = test_X[names[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the Gridsearch model with his parameter and fit on reduced dataset\n",
    "\n",
    "from sklearn.base import clone\n",
    "cloned_model = clone(grid_search.best_estimator_)\n",
    "cloned_model.fit(train_important_feature , train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced dataset scores \n",
    "\n",
    "print('Training set R2 Score - ', metrics.r2_score(train_y,cloned_model.predict(train_important_feature)))\n",
    "print('Testing set R2 Score - ', metrics.r2_score(test_y,cloned_model.predict(test_important_feature)))\n",
    "print('Testing set RMSE Score - ', np.sqrt(mean_squared_error(test_y, cloned_model.predict(test_important_feature))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations \n",
    "\n",
    "1. Based on parameter tunning step we can see that \n",
    "\n",
    "    a. 5 most important features are - 'RH_out', 'RH_8', 'RH_1', 'T3', 'RH_3'\n",
    "    \n",
    "    b. 5 least important features are - 'T7','Tdewpoint','Windspeed','T1','T5'\n",
    "    \n",
    "\n",
    "2. As can be observed with R2 Score , compared to Tuned model 0.63 the R2 score has come down to 0.47 which is decrease of 16% .\n",
    "\n",
    "\n",
    "3. The reduction in R2 score is high and we should not use reduced feature set for this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "1. The best Algorithm to use for this dataset Extra Trees Regressor\n",
    "\n",
    "2. The untuned model was able to explain 57% of variance on test set .\n",
    "\n",
    "3. The tuned model was able to explain 63% of varaince on tese set which is improvement of 10%\n",
    "\n",
    "4. The final model had 22 features \n",
    "\n",
    "5. Feature reduction was not able to add to better R2 score \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
